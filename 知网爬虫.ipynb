{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d38f2b2c-65d6-4ae2-8c53-d278c946ce75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未找到与 '中国统计年鉴' 完全匹配的<li>节点。\n",
      "数据提取时出错: Message: \n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
      "\n",
      "陕西 数据获取完成。(1/4)\n",
      "选择节点时出错: Message: Unable to locate element: ul.valueSearch_panel-body__1Mejz.valueSearch_panel-all__27BTp; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
      "\n",
      "数据提取时出错: Message: \n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
      "\n",
      "山西 数据获取完成。(2/4)\n",
      "未找到与 '中国统计年鉴' 完全匹配的<li>节点。\n",
      "数据提取时出错: Message: \n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
      "\n",
      "广西 数据获取完成。(3/4)\n",
      "未找到与 '中国统计年鉴' 完全匹配的<li>节点。\n",
      "数据提取时出错: Message: \n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
      "\n",
      "山东 数据获取完成。(4/4)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'数值'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 183\u001b[0m\n\u001b[1;32m    180\u001b[0m     driver\u001b[38;5;241m.\u001b[39mquit()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 183\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[1], line 174\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 数据获取完成。(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(cities)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    173\u001b[0m final_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(all_dfs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 174\u001b[0m final_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m数值\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(final_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m数值\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    175\u001b[0m final_df\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    177\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/zhuyenan/Downloads/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00madditional_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: '数值'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from time import sleep\n",
    "\n",
    "def save_data_to_excel(df, output_path):\n",
    "    # 将数据保存到 Excel 文件\n",
    "    df.to_excel(output_path, index=False)\n",
    "    print(f'数据已保存到 {output_path}')\n",
    "\n",
    "def initialize_driver():\n",
    "    # 设置 ChromeDriver 的路径\n",
    "    driver_path = '/Users/zhuyenan/Documents/jupyter/geckodriver'\n",
    "    # 创建 Service 对象\n",
    "    service = Service(driver_path)\n",
    "    # 创建 Chrome 浏览器对象\n",
    "    driver = webdriver.Firefox(service=service)\n",
    "    driver.implicitly_wait(3)\n",
    "    return driver\n",
    "\n",
    "def get_user_inputs():\n",
    "    additional_info = \"GDP\"\n",
    "    target_text = \"中国统计年鉴\"\n",
    "    return additional_info, target_text\n",
    "\n",
    "\n",
    "def build_url(base_url, additional_info):\n",
    "    # 构建完整的 URL\n",
    "    return f\"{base_url}{additional_info}\"\n",
    "\n",
    "def setup_initial_page(driver, url):\n",
    "    # 打开初始页面\n",
    "    driver.get(url)\n",
    "    driver.switch_to.window(driver.window_handles[-1])\n",
    "    sleep(5)\n",
    "\n",
    "def configure_search(driver):\n",
    "    # 选择精确搜索\n",
    "    model = driver.find_element(By.XPATH, '/html/body/div[5]/div[2]/div[1]/div/div[1]/div[1]/div[1]/div')\n",
    "    model.click()\n",
    "    model_select = driver.find_element(By.XPATH, '/html/body/div[5]/div[2]/div[1]/div/div[1]/div[1]/div[1]/div/div')\n",
    "    model_select.find_element(By.XPATH, \"//li/a[text()='模糊']\").click()\n",
    "\n",
    "    # 设置起始年份为2011年\n",
    "    start = driver.find_element(By.XPATH, '/html/body/div[5]/div[2]/div[1]/div/div[1]/div[1]/div[3]/div[1]/div')\n",
    "    start.click()\n",
    "    driver.execute_script(\"window.scrollBy(0, 80);\")\n",
    "    sleep(2)\n",
    "    start_select = driver.find_element(By.CSS_SELECTOR, 'div.valueSearch_primary-select__1Be9L:nth-child(2) > ul:nth-child(2)')\n",
    "    start_select.find_element(By.XPATH, \"//li/a[text()='2011']\").click()\n",
    "\n",
    "    # 设置终止年份为2021年 76=2023，\n",
    "    driver.execute_script(\"window.scrollBy(0, 80);\")\n",
    "    sleep(2)\n",
    "    end = driver.find_element(By.XPATH, '/html/body/div[5]/div[2]/div[1]/div/div[1]/div[1]/div[3]/div[2]/div')\n",
    "    end.click()\n",
    "    end_select = driver.find_element(By.CSS_SELECTOR, 'div.valueSearch_primary-select__1Be9L:nth-child(4) > ul:nth-child(2)')\n",
    "    end_select.find_element(By.XPATH, '/html/body/div[5]/div[2]/div[1]/div/div[1]/div[1]/div[3]/div[2]/ul/li[76]').click()\n",
    "\n",
    "    # 设置每页显示50条记录\n",
    "    content_number = driver.find_element(By.XPATH, '/html/body/div[5]/div[2]/div[1]/div/div[1]/div[2]/span/span[3]')\n",
    "    content_number.click()\n",
    "    sleep(3)\n",
    "\n",
    "def get_info(driver, target_text):\n",
    "    df_all = pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        driver.execute_script(\"window.scrollBy(0, 300);\")\n",
    "        # 定位到包含<li>的<ul>\n",
    "        resources = driver.find_element(By.XPATH, '/html/body/div[5]/div[2]/div[1]/div/div[2]/div[3]/div')\n",
    "        resources.click()\n",
    "        \n",
    "        # 定位包含<li>标签的<ul>\n",
    "        ul_element = driver.find_element(By.CSS_SELECTOR, \"ul.valueSearch_panel-body__1Mejz.valueSearch_panel-all__27BTp\")\n",
    "        li_elements = ul_element.find_elements(By.TAG_NAME, \"li\")  # 找到所有的<li>元素\n",
    "        found = False\n",
    "\n",
    "        # 遍历<li>元素，匹配文本\n",
    "        for li in li_elements:\n",
    "            li_text = li.text.strip()  # 获取文本并去掉空白字符\n",
    "            if target_text == li_text:\n",
    "                li.click()  # 点击匹配的<li>元素\n",
    "                sleep(2)\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if not found:\n",
    "            print(f\"未找到与 '{target_text}' 完全匹配的<li>节点。\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"选择节点时出错: {e}\")\n",
    "\n",
    "\n",
    "    # 循环获取所有页面数据\n",
    "    while True:\n",
    "        try:\n",
    "            sleep(2)\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, 'tbody.valueSearch_s-tab-tbody__1QPXw')))\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            tbody = soup.find('tbody', class_='valueSearch_s-tab-tbody__1QPXw')\n",
    "\n",
    "            rows = []\n",
    "            for tr in tbody.find_all('tr'):\n",
    "                tds = tr.find_all('td')\n",
    "                try:\n",
    "                    row = {\n",
    "                        '序号': tds[0].get_text(),\n",
    "                        '时间': tds[1].get_text(),\n",
    "                        '地区': tds[2].get_text(),\n",
    "                        '指标': tds[3].get_text(),\n",
    "                        '数值': tds[4].get_text(),\n",
    "                        '单位': tds[5].get_text(),\n",
    "                        '来源': tds[6].get_text(),\n",
    "                        '页码': tds[7].get_text(),\n",
    "                    }\n",
    "                    rows.append(row)\n",
    "                except:\n",
    "                    pass\n",
    "            df = pd.DataFrame(rows)\n",
    "            print(df)\n",
    "\n",
    "            df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "            sleep(2)\n",
    "\n",
    "            try:\n",
    "                next_button = driver.find_element(By.CLASS_NAME, \"btn-next\")\n",
    "                next_button.click()\n",
    "                sleep(7)\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"数据提取时出错: {e}\")\n",
    "            break\n",
    "\n",
    "    return df_all\n",
    "\n",
    "def main():\n",
    "    base_url = \"https://data.cnki.net/valueSearch/index?ky=\"\n",
    "    additional_info, target_text = get_user_inputs()\n",
    "    url = build_url(base_url, additional_info)\n",
    "    cities = [\n",
    "        '陕西', '山西', '广西', '山东'\n",
    "    ]\n",
    "\n",
    "    driver = initialize_driver()\n",
    "    setup_initial_page(driver, url)\n",
    "    configure_search(driver)\n",
    "\n",
    "    all_dfs = []\n",
    "    for count, city in enumerate(cities, 1):\n",
    "        driver.execute_script(\"var q=document.documentElement.scrollTop=0\")\n",
    "        search_box = driver.find_element(By.XPATH, '//*[@id=\"root\"]/div[2]/div[1]/div/div[1]/div[1]/div[2]/input')\n",
    "        search_box.clear()\n",
    "        sleep(1)\n",
    "        search_box.send_keys(city)\n",
    "        sleep(1)\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"root\"]/div[2]/div[1]/div/div[1]/div[1]/div[5]/span').click()\n",
    "        sleep(2)\n",
    "\n",
    "        df_all = get_info(driver, target_text)\n",
    "        all_dfs.append(df_all)\n",
    "\n",
    "        print(f'{city} 数据获取完成。({count}/{len(cities)})')\n",
    "\n",
    "    final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    final_df['数值'] = pd.to_numeric(final_df['数值'], errors='coerce')\n",
    "    final_df.dropna(inplace=True)\n",
    "\n",
    "    output_file_path = f\"/Users/zhuyenan/Downloads/{additional_info}.xlsx\"\n",
    "    save_data_to_excel(final_df, output_file_path)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
